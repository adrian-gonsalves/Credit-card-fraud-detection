{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "df = pd.read_csv(\"creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the % of fraud\n",
    "classes = df['Class'].value_counts()\n",
    "normal_share = classes[0]/len(df['Class'])*100\n",
    "fraud_share = classes[1]/len(df['Class'])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting % fraud\n",
    "plt.bar(['Non-Fraud','Fraud'], classes, color=['g','r'])\n",
    "plt.ylabel('Number of transactions')\n",
    "plt.annotate(\"{0:.4}%\".format(normal_share),(0.2, 0.5), xycoords='axes fraction')\n",
    "plt.annotate(\"{0:.4}%\".format(fraud_share),(0.7, 0.5), xycoords='axes fraction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the Time column\n",
    "\n",
    "df.drop('Time', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We drop the Time column since it does not provide any insight as it is just time from the 1st transaction in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Class']\n",
    "X = df.drop('Class', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with imbalance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_clf = LogisticRegression(random_state = 21)\n",
    "\n",
    "params = {'C': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]}\n",
    "\n",
    "\n",
    "logistic_model = GridSearchCV(estimator=logistic_clf, \n",
    "                              param_grid=params, \n",
    "                              n_jobs=-1, \n",
    "                              cv=3, \n",
    "                              scoring='roc_auc', \n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 7 candidates, totalling 21 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=LogisticRegression(random_state=21), n_jobs=-1,\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]},\n",
       "             scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "logistic_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.081835</td>\n",
       "      <td>0.129849</td>\n",
       "      <td>0.058005</td>\n",
       "      <td>0.004241</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 0.001}</td>\n",
       "      <td>0.983947</td>\n",
       "      <td>0.980332</td>\n",
       "      <td>0.984888</td>\n",
       "      <td>0.983056</td>\n",
       "      <td>0.001964</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.878163</td>\n",
       "      <td>0.090267</td>\n",
       "      <td>0.059679</td>\n",
       "      <td>0.005551</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>0.978500</td>\n",
       "      <td>0.979696</td>\n",
       "      <td>0.985747</td>\n",
       "      <td>0.981314</td>\n",
       "      <td>0.003172</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.876498</td>\n",
       "      <td>0.325253</td>\n",
       "      <td>0.060212</td>\n",
       "      <td>0.004236</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.1}</td>\n",
       "      <td>0.952480</td>\n",
       "      <td>0.968933</td>\n",
       "      <td>0.928313</td>\n",
       "      <td>0.949909</td>\n",
       "      <td>0.016683</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.824281</td>\n",
       "      <td>0.163174</td>\n",
       "      <td>0.056532</td>\n",
       "      <td>0.004950</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'C': 1.0}</td>\n",
       "      <td>0.958280</td>\n",
       "      <td>0.959118</td>\n",
       "      <td>0.937411</td>\n",
       "      <td>0.951603</td>\n",
       "      <td>0.010041</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.782426</td>\n",
       "      <td>0.202301</td>\n",
       "      <td>0.060010</td>\n",
       "      <td>0.004543</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{'C': 10.0}</td>\n",
       "      <td>0.947979</td>\n",
       "      <td>0.958682</td>\n",
       "      <td>0.931805</td>\n",
       "      <td>0.946155</td>\n",
       "      <td>0.011048</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.807000</td>\n",
       "      <td>0.827768</td>\n",
       "      <td>0.046216</td>\n",
       "      <td>0.005830</td>\n",
       "      <td>100.0</td>\n",
       "      <td>{'C': 100.0}</td>\n",
       "      <td>0.957391</td>\n",
       "      <td>0.957923</td>\n",
       "      <td>0.932957</td>\n",
       "      <td>0.949424</td>\n",
       "      <td>0.011646</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.177543</td>\n",
       "      <td>0.110828</td>\n",
       "      <td>0.032520</td>\n",
       "      <td>0.003910</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>{'C': 1000.0}</td>\n",
       "      <td>0.950472</td>\n",
       "      <td>0.952350</td>\n",
       "      <td>0.935091</td>\n",
       "      <td>0.945971</td>\n",
       "      <td>0.007731</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       6.081835      0.129849         0.058005        0.004241   0.001   \n",
       "1       5.878163      0.090267         0.059679        0.005551    0.01   \n",
       "2       5.876498      0.325253         0.060212        0.004236     0.1   \n",
       "3       5.824281      0.163174         0.056532        0.004950     1.0   \n",
       "4       5.782426      0.202301         0.060010        0.004543    10.0   \n",
       "5       4.807000      0.827768         0.046216        0.005830   100.0   \n",
       "6       4.177543      0.110828         0.032520        0.003910  1000.0   \n",
       "\n",
       "          params  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0   {'C': 0.001}           0.983947           0.980332           0.984888   \n",
       "1    {'C': 0.01}           0.978500           0.979696           0.985747   \n",
       "2     {'C': 0.1}           0.952480           0.968933           0.928313   \n",
       "3     {'C': 1.0}           0.958280           0.959118           0.937411   \n",
       "4    {'C': 10.0}           0.947979           0.958682           0.931805   \n",
       "5   {'C': 100.0}           0.957391           0.957923           0.932957   \n",
       "6  {'C': 1000.0}           0.950472           0.952350           0.935091   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.983056        0.001964                1  \n",
       "1         0.981314        0.003172                2  \n",
       "2         0.949909        0.016683                4  \n",
       "3         0.951603        0.010041                3  \n",
       "4         0.946155        0.011048                6  \n",
       "5         0.949424        0.011646                5  \n",
       "6         0.945971        0.007731                7  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_cv = pd.DataFrame(logistic_model.cv_results_)\n",
    "logistic_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C: {'C': 0.001} Best score: 0.9830555398738171\n"
     ]
    }
   ],
   "source": [
    "# best params\n",
    "print('Best C:',logistic_model.best_params_, 'Best score:', logistic_model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with imbalance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(random_state=21)\n",
    "\n",
    "params = { \n",
    "    'n_estimators': range(800, 1000, 25)\n",
    "}\n",
    "\n",
    "rf_model = GridSearchCV(estimator=rf_clf, \n",
    "                              param_grid=params, \n",
    "                              n_jobs=-1, \n",
    "                              cv=3, \n",
    "                              scoring='roc_auc', \n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(random_state=21), n_jobs=-1,\n",
       "             param_grid={'n_estimators': range(800, 1000, 25)},\n",
       "             scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1390.870162</td>\n",
       "      <td>31.024203</td>\n",
       "      <td>8.286236</td>\n",
       "      <td>0.311386</td>\n",
       "      <td>800</td>\n",
       "      <td>{'n_estimators': 800}</td>\n",
       "      <td>0.941883</td>\n",
       "      <td>0.949289</td>\n",
       "      <td>0.979099</td>\n",
       "      <td>0.956757</td>\n",
       "      <td>0.016085</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1439.848358</td>\n",
       "      <td>46.303473</td>\n",
       "      <td>8.449965</td>\n",
       "      <td>0.203309</td>\n",
       "      <td>825</td>\n",
       "      <td>{'n_estimators': 825}</td>\n",
       "      <td>0.941790</td>\n",
       "      <td>0.949155</td>\n",
       "      <td>0.979008</td>\n",
       "      <td>0.956651</td>\n",
       "      <td>0.016092</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1481.550199</td>\n",
       "      <td>37.956482</td>\n",
       "      <td>8.873319</td>\n",
       "      <td>0.314168</td>\n",
       "      <td>850</td>\n",
       "      <td>{'n_estimators': 850}</td>\n",
       "      <td>0.941726</td>\n",
       "      <td>0.949058</td>\n",
       "      <td>0.978915</td>\n",
       "      <td>0.956566</td>\n",
       "      <td>0.016084</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1521.572589</td>\n",
       "      <td>41.192317</td>\n",
       "      <td>10.143947</td>\n",
       "      <td>0.235471</td>\n",
       "      <td>875</td>\n",
       "      <td>{'n_estimators': 875}</td>\n",
       "      <td>0.945532</td>\n",
       "      <td>0.952879</td>\n",
       "      <td>0.978922</td>\n",
       "      <td>0.959111</td>\n",
       "      <td>0.014326</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1596.480062</td>\n",
       "      <td>37.459927</td>\n",
       "      <td>10.449423</td>\n",
       "      <td>1.202968</td>\n",
       "      <td>900</td>\n",
       "      <td>{'n_estimators': 900}</td>\n",
       "      <td>0.949426</td>\n",
       "      <td>0.956660</td>\n",
       "      <td>0.978826</td>\n",
       "      <td>0.961638</td>\n",
       "      <td>0.012508</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1760.557189</td>\n",
       "      <td>105.352280</td>\n",
       "      <td>10.497409</td>\n",
       "      <td>0.711063</td>\n",
       "      <td>925</td>\n",
       "      <td>{'n_estimators': 925}</td>\n",
       "      <td>0.949339</td>\n",
       "      <td>0.956542</td>\n",
       "      <td>0.978849</td>\n",
       "      <td>0.961577</td>\n",
       "      <td>0.012562</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1806.844435</td>\n",
       "      <td>6.721238</td>\n",
       "      <td>8.288774</td>\n",
       "      <td>0.450208</td>\n",
       "      <td>950</td>\n",
       "      <td>{'n_estimators': 950}</td>\n",
       "      <td>0.949246</td>\n",
       "      <td>0.956434</td>\n",
       "      <td>0.978766</td>\n",
       "      <td>0.961482</td>\n",
       "      <td>0.012569</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1813.741253</td>\n",
       "      <td>43.524757</td>\n",
       "      <td>6.883639</td>\n",
       "      <td>0.193804</td>\n",
       "      <td>975</td>\n",
       "      <td>{'n_estimators': 975}</td>\n",
       "      <td>0.949168</td>\n",
       "      <td>0.956353</td>\n",
       "      <td>0.978674</td>\n",
       "      <td>0.961398</td>\n",
       "      <td>0.012563</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0    1390.870162     31.024203         8.286236        0.311386   \n",
       "1    1439.848358     46.303473         8.449965        0.203309   \n",
       "2    1481.550199     37.956482         8.873319        0.314168   \n",
       "3    1521.572589     41.192317        10.143947        0.235471   \n",
       "4    1596.480062     37.459927        10.449423        1.202968   \n",
       "5    1760.557189    105.352280        10.497409        0.711063   \n",
       "6    1806.844435      6.721238         8.288774        0.450208   \n",
       "7    1813.741253     43.524757         6.883639        0.193804   \n",
       "\n",
       "  param_n_estimators                 params  split0_test_score  \\\n",
       "0                800  {'n_estimators': 800}           0.941883   \n",
       "1                825  {'n_estimators': 825}           0.941790   \n",
       "2                850  {'n_estimators': 850}           0.941726   \n",
       "3                875  {'n_estimators': 875}           0.945532   \n",
       "4                900  {'n_estimators': 900}           0.949426   \n",
       "5                925  {'n_estimators': 925}           0.949339   \n",
       "6                950  {'n_estimators': 950}           0.949246   \n",
       "7                975  {'n_estimators': 975}           0.949168   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.949289           0.979099         0.956757        0.016085   \n",
       "1           0.949155           0.979008         0.956651        0.016092   \n",
       "2           0.949058           0.978915         0.956566        0.016084   \n",
       "3           0.952879           0.978922         0.959111        0.014326   \n",
       "4           0.956660           0.978826         0.961638        0.012508   \n",
       "5           0.956542           0.978849         0.961577        0.012562   \n",
       "6           0.956434           0.978766         0.961482        0.012569   \n",
       "7           0.956353           0.978674         0.961398        0.012563   \n",
       "\n",
       "   rank_test_score  \n",
       "0                6  \n",
       "1                7  \n",
       "2                8  \n",
       "3                5  \n",
       "4                1  \n",
       "5                2  \n",
       "6                3  \n",
       "7                4  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cv = pd.DataFrame(rf_model.cv_results_)\n",
    "rf_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C: {'n_estimators': 900} Best score: 0.9616376272828718\n"
     ]
    }
   ],
   "source": [
    "# best params\n",
    "print('Best C:',rf_model.best_params_, 'Best score:', rf_model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost with imbalance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_clf = XGBClassifier(max_depth=2, random_state = 21)\n",
    "\n",
    "params = {'learning_rate': [0.1, 0.2, 0.3],\n",
    "         'n_estimators': [1000, 1100]}\n",
    "\n",
    "xgb_model = GridSearchCV(estimator=xgb_clf, \n",
    "                              param_grid=params, \n",
    "                              n_jobs=-1, \n",
    "                              cv=3, \n",
    "                              scoring='roc_auc', \n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "[23:16:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=2, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, random_state=21,\n",
       "                                     reg_alpha=None, reg_lambda=None,\n",
       "                                     scale_pos_weight=None, subsample=None,\n",
       "                                     tree_method=None, validate_parameters=None,\n",
       "                                     verbosity=None),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.1, 0.2, 0.3],\n",
       "                         'n_estimators': [1000, 1100]},\n",
       "             scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>531.890347</td>\n",
       "      <td>36.478703</td>\n",
       "      <td>0.422012</td>\n",
       "      <td>0.011202</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 1000}</td>\n",
       "      <td>0.973107</td>\n",
       "      <td>0.974160</td>\n",
       "      <td>0.977946</td>\n",
       "      <td>0.975071</td>\n",
       "      <td>0.002078</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>586.452870</td>\n",
       "      <td>40.956964</td>\n",
       "      <td>0.527289</td>\n",
       "      <td>0.074200</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1100</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 1100}</td>\n",
       "      <td>0.972498</td>\n",
       "      <td>0.974714</td>\n",
       "      <td>0.977790</td>\n",
       "      <td>0.975001</td>\n",
       "      <td>0.002170</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>474.530606</td>\n",
       "      <td>7.342274</td>\n",
       "      <td>0.457040</td>\n",
       "      <td>0.042131</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'learning_rate': 0.2, 'n_estimators': 1000}</td>\n",
       "      <td>0.970586</td>\n",
       "      <td>0.973681</td>\n",
       "      <td>0.975356</td>\n",
       "      <td>0.973208</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>514.087442</td>\n",
       "      <td>6.190605</td>\n",
       "      <td>0.558208</td>\n",
       "      <td>0.033032</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1100</td>\n",
       "      <td>{'learning_rate': 0.2, 'n_estimators': 1100}</td>\n",
       "      <td>0.970820</td>\n",
       "      <td>0.974032</td>\n",
       "      <td>0.974853</td>\n",
       "      <td>0.973235</td>\n",
       "      <td>0.001740</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>444.184986</td>\n",
       "      <td>17.577493</td>\n",
       "      <td>0.396198</td>\n",
       "      <td>0.039300</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'learning_rate': 0.3, 'n_estimators': 1000}</td>\n",
       "      <td>0.970262</td>\n",
       "      <td>0.975201</td>\n",
       "      <td>0.978739</td>\n",
       "      <td>0.974734</td>\n",
       "      <td>0.003476</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>258.646256</td>\n",
       "      <td>117.754579</td>\n",
       "      <td>0.241265</td>\n",
       "      <td>0.051098</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1100</td>\n",
       "      <td>{'learning_rate': 0.3, 'n_estimators': 1100}</td>\n",
       "      <td>0.970149</td>\n",
       "      <td>0.975213</td>\n",
       "      <td>0.978660</td>\n",
       "      <td>0.974674</td>\n",
       "      <td>0.003495</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0     531.890347     36.478703         0.422012        0.011202   \n",
       "1     586.452870     40.956964         0.527289        0.074200   \n",
       "2     474.530606      7.342274         0.457040        0.042131   \n",
       "3     514.087442      6.190605         0.558208        0.033032   \n",
       "4     444.184986     17.577493         0.396198        0.039300   \n",
       "5     258.646256    117.754579         0.241265        0.051098   \n",
       "\n",
       "  param_learning_rate param_n_estimators  \\\n",
       "0                 0.1               1000   \n",
       "1                 0.1               1100   \n",
       "2                 0.2               1000   \n",
       "3                 0.2               1100   \n",
       "4                 0.3               1000   \n",
       "5                 0.3               1100   \n",
       "\n",
       "                                         params  split0_test_score  \\\n",
       "0  {'learning_rate': 0.1, 'n_estimators': 1000}           0.973107   \n",
       "1  {'learning_rate': 0.1, 'n_estimators': 1100}           0.972498   \n",
       "2  {'learning_rate': 0.2, 'n_estimators': 1000}           0.970586   \n",
       "3  {'learning_rate': 0.2, 'n_estimators': 1100}           0.970820   \n",
       "4  {'learning_rate': 0.3, 'n_estimators': 1000}           0.970262   \n",
       "5  {'learning_rate': 0.3, 'n_estimators': 1100}           0.970149   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.974160           0.977946         0.975071        0.002078   \n",
       "1           0.974714           0.977790         0.975001        0.002170   \n",
       "2           0.973681           0.975356         0.973208        0.001976   \n",
       "3           0.974032           0.974853         0.973235        0.001740   \n",
       "4           0.975201           0.978739         0.974734        0.003476   \n",
       "5           0.975213           0.978660         0.974674        0.003495   \n",
       "\n",
       "   rank_test_score  \n",
       "0                1  \n",
       "1                2  \n",
       "2                6  \n",
       "3                5  \n",
       "4                3  \n",
       "5                4  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_cv = pd.DataFrame(xgb_model.cv_results_)\n",
    "xgb_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C: {'learning_rate': 0.1, 'n_estimators': 1000} Best score: 0.9750712235644278\n"
     ]
    }
   ],
   "source": [
    "# best params\n",
    "print('Best C:',xgb_model.best_params_, 'Best score:', xgb_model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above 3 model we can see that logistic regression has the best ROC AUC with 0.9830."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9820901214119135"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict on test data\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# logistic regression\n",
    "logistic_test_score = roc_auc_score(y_test,logistic_model.predict_proba(x_test)[:, 1])\n",
    "logistic_test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9757653713370799"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random forest\n",
    "rf_test_score = roc_auc_score(y_test,rf_model.predict_proba(x_test)[:, 1])\n",
    "rf_test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9832964969585541"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xgboost\n",
    "xgb_test_score = roc_auc_score(y_test,xgb_model.predict_proba(x_test)[:, 1])\n",
    "xgb_test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building with balancing Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369\n",
      "213236\n"
     ]
    }
   ],
   "source": [
    "# balancing the dataset using smote\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=21)\n",
    "x_train_smote, y_train_smote = smote.fit_resample(x_train, y_train)\n",
    "\n",
    "print(np.sum(y_train))\n",
    "print(np.sum(y_train_smote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.0\n"
     ]
    }
   ],
   "source": [
    "# % of Fraud rows\n",
    "print(100*(np.sum(y_train_smote)/len(y_train_smote)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with balanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression\n",
    "\n",
    "logistic_clf_smote = LogisticRegression(random_state = 21)\n",
    "\n",
    "params = {'C': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]}\n",
    "\n",
    "\n",
    "logistic_model_smote = GridSearchCV(estimator=logistic_clf_smote, \n",
    "                              param_grid=params, \n",
    "                              n_jobs=-1, \n",
    "                              cv=3, \n",
    "                              scoring='roc_auc', \n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 7 candidates, totalling 21 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=LogisticRegression(random_state=21), n_jobs=-1,\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]},\n",
       "             scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_model_smote.fit(x_train_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.416516</td>\n",
       "      <td>0.531453</td>\n",
       "      <td>0.115969</td>\n",
       "      <td>0.015035</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 0.001}</td>\n",
       "      <td>0.992387</td>\n",
       "      <td>0.992705</td>\n",
       "      <td>0.992230</td>\n",
       "      <td>0.992441</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.583195</td>\n",
       "      <td>0.614831</td>\n",
       "      <td>0.119118</td>\n",
       "      <td>0.005258</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>0.992411</td>\n",
       "      <td>0.992641</td>\n",
       "      <td>0.992577</td>\n",
       "      <td>0.992543</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.986772</td>\n",
       "      <td>0.204291</td>\n",
       "      <td>0.125656</td>\n",
       "      <td>0.007583</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.1}</td>\n",
       "      <td>0.992067</td>\n",
       "      <td>0.992551</td>\n",
       "      <td>0.992356</td>\n",
       "      <td>0.992325</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.609098</td>\n",
       "      <td>0.409860</td>\n",
       "      <td>0.114005</td>\n",
       "      <td>0.010987</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'C': 1.0}</td>\n",
       "      <td>0.992325</td>\n",
       "      <td>0.992335</td>\n",
       "      <td>0.992428</td>\n",
       "      <td>0.992363</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.143300</td>\n",
       "      <td>0.148325</td>\n",
       "      <td>0.123179</td>\n",
       "      <td>0.009358</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{'C': 10.0}</td>\n",
       "      <td>0.992541</td>\n",
       "      <td>0.992792</td>\n",
       "      <td>0.992184</td>\n",
       "      <td>0.992506</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.191623</td>\n",
       "      <td>1.362498</td>\n",
       "      <td>0.085496</td>\n",
       "      <td>0.007251</td>\n",
       "      <td>100.0</td>\n",
       "      <td>{'C': 100.0}</td>\n",
       "      <td>0.992270</td>\n",
       "      <td>0.992439</td>\n",
       "      <td>0.992086</td>\n",
       "      <td>0.992265</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.876444</td>\n",
       "      <td>0.374485</td>\n",
       "      <td>0.068096</td>\n",
       "      <td>0.015348</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>{'C': 1000.0}</td>\n",
       "      <td>0.992457</td>\n",
       "      <td>0.992321</td>\n",
       "      <td>0.992613</td>\n",
       "      <td>0.992464</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0      11.416516      0.531453         0.115969        0.015035   0.001   \n",
       "1      10.583195      0.614831         0.119118        0.005258    0.01   \n",
       "2       9.986772      0.204291         0.125656        0.007583     0.1   \n",
       "3      10.609098      0.409860         0.114005        0.010987     1.0   \n",
       "4      11.143300      0.148325         0.123179        0.009358    10.0   \n",
       "5       9.191623      1.362498         0.085496        0.007251   100.0   \n",
       "6       7.876444      0.374485         0.068096        0.015348  1000.0   \n",
       "\n",
       "          params  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0   {'C': 0.001}           0.992387           0.992705           0.992230   \n",
       "1    {'C': 0.01}           0.992411           0.992641           0.992577   \n",
       "2     {'C': 0.1}           0.992067           0.992551           0.992356   \n",
       "3     {'C': 1.0}           0.992325           0.992335           0.992428   \n",
       "4    {'C': 10.0}           0.992541           0.992792           0.992184   \n",
       "5   {'C': 100.0}           0.992270           0.992439           0.992086   \n",
       "6  {'C': 1000.0}           0.992457           0.992321           0.992613   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.992441        0.000198                4  \n",
       "1         0.992543        0.000097                1  \n",
       "2         0.992325        0.000199                6  \n",
       "3         0.992363        0.000046                5  \n",
       "4         0.992506        0.000250                2  \n",
       "5         0.992265        0.000144                7  \n",
       "6         0.992464        0.000119                3  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_cv_smote = pd.DataFrame(logistic_model_smote.cv_results_)\n",
    "logistic_cv_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C: {'C': 0.01} Best score: 0.9925433825281628\n"
     ]
    }
   ],
   "source": [
    "# best params\n",
    "print('Best C:',logistic_model_smote.best_params_, 'Best score:', logistic_model_smote.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "\n",
    "rf_clf_smote = RandomForestClassifier(random_state=21)\n",
    "\n",
    "params = { \n",
    "    'n_estimators': [900, 1000]\n",
    "}\n",
    "\n",
    "rf_model_smote = GridSearchCV(estimator=rf_clf_smote, \n",
    "                              param_grid=params, \n",
    "                              n_jobs=-1, \n",
    "                              cv=3, \n",
    "                              scoring='roc_auc', \n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(random_state=21), n_jobs=-1,\n",
       "             param_grid={'n_estimators': [900, 1000]}, scoring='roc_auc',\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model_smote.fit(x_train_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2717.010131</td>\n",
       "      <td>4.439747</td>\n",
       "      <td>23.535657</td>\n",
       "      <td>0.587914</td>\n",
       "      <td>900</td>\n",
       "      <td>{'n_estimators': 900}</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>4.557029e-07</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2960.386189</td>\n",
       "      <td>4.222565</td>\n",
       "      <td>20.932640</td>\n",
       "      <td>0.240322</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'n_estimators': 1000}</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>4.116611e-07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0    2717.010131      4.439747        23.535657        0.587914   \n",
       "1    2960.386189      4.222565        20.932640        0.240322   \n",
       "\n",
       "  param_n_estimators                  params  split0_test_score  \\\n",
       "0                900   {'n_estimators': 900}           0.999999   \n",
       "1               1000  {'n_estimators': 1000}           0.999999   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.999998           0.999998         0.999998    4.557029e-07   \n",
       "1           0.999998           0.999998         0.999998    4.116611e-07   \n",
       "\n",
       "   rank_test_score  \n",
       "0                2  \n",
       "1                1  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cv_smote = pd.DataFrame(rf_model_smote.cv_results_)\n",
    "rf_cv_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C: {'n_estimators': 1000} Best score: 0.9999982358078827\n"
     ]
    }
   ],
   "source": [
    "# best params\n",
    "print('Best C:',rf_model_smote.best_params_, 'Best score:', rf_model_smote.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "\n",
    "xgb_clf_smote = XGBClassifier(max_depth=2, random_state = 21, tree_method = 'gpu_hist')\n",
    "\n",
    "params = {'learning_rate': [0.1, 0.2, 0.3],\n",
    "         'n_estimators': [1000]}\n",
    "\n",
    "xgb_model_smote = GridSearchCV(estimator=xgb_clf_smote, \n",
    "                              param_grid=params, \n",
    "                              n_jobs=-1, \n",
    "                              cv=3, \n",
    "                              scoring='roc_auc', \n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[22:47:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=2, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, random_state=21,\n",
       "                                     reg_alpha=None, reg_lambda=None,\n",
       "                                     scale_pos_weight=None, subsample=None,\n",
       "                                     tree_method='gpu_hist',\n",
       "                                     validate_parameters=None, verbosity=None),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.1, 0.2, 0.3],\n",
       "                         'n_estimators': [1000]},\n",
       "             scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model_smote.fit(x_train_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54.275985</td>\n",
       "      <td>1.434978</td>\n",
       "      <td>1.165062</td>\n",
       "      <td>0.328376</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 1000}</td>\n",
       "      <td>0.999961</td>\n",
       "      <td>0.999956</td>\n",
       "      <td>0.999956</td>\n",
       "      <td>0.999958</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54.985056</td>\n",
       "      <td>0.736854</td>\n",
       "      <td>0.910391</td>\n",
       "      <td>0.225451</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'learning_rate': 0.2, 'n_estimators': 1000}</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37.305559</td>\n",
       "      <td>20.633978</td>\n",
       "      <td>1.166847</td>\n",
       "      <td>0.564290</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'learning_rate': 0.3, 'n_estimators': 1000}</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      54.275985      1.434978         1.165062        0.328376   \n",
       "1      54.985056      0.736854         0.910391        0.225451   \n",
       "2      37.305559     20.633978         1.166847        0.564290   \n",
       "\n",
       "  param_learning_rate param_n_estimators  \\\n",
       "0                 0.1               1000   \n",
       "1                 0.2               1000   \n",
       "2                 0.3               1000   \n",
       "\n",
       "                                         params  split0_test_score  \\\n",
       "0  {'learning_rate': 0.1, 'n_estimators': 1000}           0.999961   \n",
       "1  {'learning_rate': 0.2, 'n_estimators': 1000}           0.999983   \n",
       "2  {'learning_rate': 0.3, 'n_estimators': 1000}           0.999986   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.999956           0.999956         0.999958        0.000002   \n",
       "1           0.999980           0.999986         0.999983        0.000002   \n",
       "2           0.999983           0.999991         0.999987        0.000003   \n",
       "\n",
       "   rank_test_score  \n",
       "0                3  \n",
       "1                2  \n",
       "2                1  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_cv_smote = pd.DataFrame(xgb_model_smote.cv_results_)\n",
    "xgb_cv_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C: {'learning_rate': 0.3, 'n_estimators': 1000} Best score: 0.9999865042364462\n"
     ]
    }
   ],
   "source": [
    "# best params\n",
    "print('Best C:',xgb_model_smote.best_params_, 'Best score:', xgb_model_smote.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see after using a balanced data the ROC AUC score imporves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9806012249967602"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict on test data\n",
    "\n",
    "# logistic regression\n",
    "logistic_test_score_smote = roc_auc_score(y_test,logistic_model_smote.predict_proba(x_test)[:, 1])\n",
    "logistic_test_score_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9872519034986492"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random forest\n",
    "rf_test_score_smote = roc_auc_score(y_test,rf_model_smote.predict_proba(x_test)[:, 1])\n",
    "rf_test_score_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9809216059492717"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xgboost\n",
    "xgb_test_score_smote = roc_auc_score(y_test,xgb_model_smote.predict_proba(x_test)[:, 1])\n",
    "xgb_test_score_smote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTE with Random Forest gives the best ROC AUC score of 98.72 on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find out the threshold\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_train_smote,rf_model_smote.predict_proba(x_train_smote)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.889\n"
     ]
    }
   ],
   "source": [
    "threshold = thresholds[np.argmax(tpr-fpr)]\n",
    "print(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x1896b9b0408>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_roc_curve\n",
    "\n",
    "plot_roc_curve(rf_model_smote.best_estimator_, x_train_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
